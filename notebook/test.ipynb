{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from chromedriver_py import binary_path # this will get you the path variable\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "REPO_DIR = os.path.dirname(os.path.abspath(''))\n",
    "BASE_URL = \"https://fr.investing.com/commodities/crude-oil-news\"\n",
    "DATA_DIR = os.path.join(REPO_DIR, \"data/\")\n",
    "\n",
    "FILE_PATH = os.path.join(DATA_DIR, \"articles/output.csv\")\n",
    "\n",
    "\n",
    "def load_configs():\n",
    "    #dotenv_path = os.path.join(env_file_location_dir, '.env')\n",
    "    #load_dotenv(dotenv_path)\n",
    "\n",
    "    #chrome_driver = os.environ.get(\"CHROME_DRIVER\")\n",
    "    #user_agent = os.environ.get(\"USER_AGENT\")\n",
    "    #return chrome_driver, user_agent\n",
    "    pass \n",
    "\n",
    "def get_driver():\n",
    "    #configs = load_configs()\n",
    "    #if isinstance(configs, tuple):\n",
    "        # local env dev\n",
    "    #chrome_driver_path, user_agent = configs\n",
    "    #print(chrome_driver_path)\n",
    "    driver = webdriver.Chrome(binary_path)\n",
    "    return driver\n",
    "\n",
    "def __get_titles(driver):\n",
    "        return [s.text for s in driver.find_elements_by_class_name(\"title\")][3:13]\n",
    "    \n",
    "def __get_dates(driver):\n",
    "        return [s.text for  s in driver.find_elements_by_xpath('.//span[@class = \"date\"]')]\n",
    "    \n",
    "def format_string(s):\n",
    "    return s.replace(' - ','')\n",
    "\n",
    "def format_date(dates):\n",
    "    return list(map(format_string, dates))\n",
    "\n",
    "def scrape(base_url, page):\n",
    "    url = base_url + '/'+ str(page)\n",
    "    driver = get_driver()\n",
    "    driver.get(url)\n",
    "    titles = __get_titles(driver)\n",
    "    dates = __get_dates(driver)\n",
    "    dates = format_date(dates)\n",
    "    return titles, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(BASE_URL, nb):\n",
    "    pages = []\n",
    "    for i in range(1,nb+1):\n",
    "        j = BASE_URL + str(i)\n",
    "        pages.append(j)\n",
    "    return pages\n",
    "pages = get_pages(BASE_URL,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://fr.investing.com/commodities/crude-oil-news2', 'https://fr.investing.com/commodities/crude-oil-news3', 'https://fr.investing.com/commodities/crude-oil-news4', 'https://fr.investing.com/commodities/crude-oil-news5', 'https://fr.investing.com/commodities/crude-oil-news6', 'https://fr.investing.com/commodities/crude-oil-news7', 'https://fr.investing.com/commodities/crude-oil-news8', 'https://fr.investing.com/commodities/crude-oil-news9', 'https://fr.investing.com/commodities/crude-oil-news10']\n"
     ]
    }
   ],
   "source": [
    "print(pages[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrapes(pages):\n",
    "    #url = base_url + '/'+ str(page)\n",
    "    driver = get_driver()\n",
    "    driver.get(pages)\n",
    "    titles = __get_titles(driver)\n",
    "    dates = __get_dates(driver)\n",
    "    dates = format_date(dates)\n",
    "    return titles, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-33-ef5122352632>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-ef5122352632>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    titles, dates = scrapes(pages[i])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "titles, dates = scrapes(pages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titles, dates = scrape(base_url=BASE_URL, page=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_news(titles, dates, file_path):\n",
    "    with open(file_path, \"w\") as csv_file:\n",
    "        for title, date in zip(titles, dates):\n",
    "            csv_file.write(title)\n",
    "            csv_file.write(\"|\")\n",
    "            csv_file.write(date)   \n",
    "            csv_file.write(\"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_news(titles, dates, file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 'https://www.expat-dakar.com/appartements-a-louer?page='\n",
    "def get_pages(token, nb):\n",
    "    pages = []\n",
    "    for i in range(1,nb+1):\n",
    "        j = token + str(i)\n",
    "        pages.append(j)\n",
    "    return pages\n",
    "pages = get_pages(token,38)\n",
    "\n",
    "import requests\n",
    "for i in pages:\n",
    "   response = requests.get(i ,headers=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
